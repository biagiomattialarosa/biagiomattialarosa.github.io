---
layout: page
title: Neuron Alignment
description: This research area aims to understand what deep neural networks learn during the training process. Specifically, we are interested on analyzing the behavior of individual neurons and groups of neurons and discovering the concepts they learn to recognize and the relationships between these concepts. 
img: assets/img/neurons.jpg
importance: 2
category: available
related_publications: true
---
This page provides a summary sheet that includes the general goal, reference papers (both mine and external) for an overview of the topic, as well as the domains explored so far. We are also interested in extending the applications of these techniques beyond their traditional domains. If you have expertise in other areas (e.g., neuroscience, gaming, or audio/speech modeling), we would be happy to explore potential extensions into those fields.

**Goal**: The goal of this research area is to understand what deep neural networks learn during the training process. My research focuses on capturing the alignment between neurons activations and human-defined knowledge (e.g., concepts). These methods typically combine tools from classical AI (e.g., heuristic search and clustering), statistical analysis, and recent advancements in AI.

**Domains**: NLP, Vision. 

**Reference Papers**: 
1. Compositional Explanations: [<a href="https://arxiv.org/abs/2006.14032">Seminal Paper</a>]
2. Clustered Compositional Explanations: [{% cite LaRosa2023Towards %}]
3. Open Vocabulary Compoisitional Explanations: [{% cite LaRosa2025open %}]
4. Optimal Compositional Explanations: [{% cite LaRosa2025optimal %}]
2. Metrics : [{% cite Makinwa2022 %}]


